{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch 101_ComputerVision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gQXaOBBo1oW",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch 101"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEp40UvmAmPK",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyE2ltG3Auin",
        "colab_type": "text"
      },
      "source": [
        "**PyTorch** is the **fastest growing** Deep Learning framework and it is also used by **Fast.ai** in its MOOC, [Deep Learning for Coders](https://course.fast.ai/) and its [library](https://docs.fast.ai/).\n",
        "\n",
        "PyTorch is also very *pythonic*, meaning, it feels more natural to use it if you already are a Python developer.\n",
        "\n",
        "Besides, using PyTorch may even improve your health, according to [Andrej Karpathy](https://twitter.com/karpathy/status/868178954032513024) :-)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSt6oP0rA_FG",
        "colab_type": "text"
      },
      "source": [
        "## Motivation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPZG7RmuBCv0",
        "colab_type": "text"
      },
      "source": [
        "There are *many many* PyTorch tutorials around and its documentation is quite complete and extensive. So, **why** should you keep reading this step-by-step tutorial?\n",
        "\n",
        "Well, even though one can find information on pretty much anything PyTorch can do, I missed having a **structured, incremental and from first principles** approach to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2ITAYVZf69n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwmMttjrfl3j",
        "colab_type": "text"
      },
      "source": [
        "## TorchVision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oQof5AafziT",
        "colab_type": "text"
      },
      "source": [
        "[Torchvision](https://pytorch.org/docs/stable/torchvision/index.html) is a package containing popular datasets, model architectures and common image transformations for computer vision."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kodc3GopgsEL",
        "colab_type": "text"
      },
      "source": [
        "### Datasets\n",
        "\n",
        "All [datasets](https://pytorch.org/docs/stable/torchvision/datasets.html) included in torchvision are subclasses of the [**Dataset**](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class we've seen earlier in this tutorial, so we can stick with the [**DataLoader**](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) as well.\n",
        "\n",
        "We'll work with the canonical dataset for computer vision tutorials: [**MNIST**](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist).\n",
        "\n",
        "**Training Set**\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "\n",
        "**Test Set**\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "\n",
        "http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbTt-k5Jhm7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "mnist_train = datasets.MNIST('./mnist', train=True, download=True)\n",
        "mnist_test = datasets.MNIST('./mnist', train=False, download=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ocJ8tdbhxTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKSUAcReh_fX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train.data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB39bOA3iEK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist_train.targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXxOwHui-SDy",
        "colab_type": "text"
      },
      "source": [
        "There are 60k 28x28 images and the targets are the corresponding digits.\n",
        "\n",
        "Let's take a look at the first sample, which is a **5**. You'll notice that, somewhat unsurprisingly, the sample is a **tensor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzft4CGiesa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_tensor = mnist_train.data[0]\n",
        "plt.imshow(sample_tensor)\n",
        "print(sample_tensor.type())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a_B_srP_RLL",
        "colab_type": "text"
      },
      "source": [
        "### Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxQe08L7_TJ3",
        "colab_type": "text"
      },
      "source": [
        "Torchvision has some common image transformations on its [**transforms**](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision-transforms) module. It is important to realize there are two main groups of transformations:\n",
        "\n",
        "- transformations based on [**PIL images**](https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-pil-image)\n",
        "- transformations based on [**Tensors**](https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-torch-tensor)\n",
        "\n",
        "Obviously, there are transformations to convert from tensors [**ToPILImage**](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToPILImage) and from PIL image [**ToTensor**](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.ToTensor).\n",
        "\n",
        "Let's try converting our sample tensor into a sample (PIL) image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4cEG1xiioLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import ToPILImage\n",
        "\n",
        "sample_img = ToPILImage()(sample_tensor)\n",
        "plt.imshow(sample_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5QUm376BOMT",
        "colab_type": "text"
      },
      "source": [
        "### Transforms on PIL Image\n",
        "\n",
        "These transforms include the typical things you'd like to do with an image: [Resize](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Resize), [CenterCrop](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.CenterCrop), [GrayScale](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Grayscale), [RandomHorizontalFlip](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomHorizontalFlip), to name a few.\n",
        "\n",
        "They take a **PIL Image** as inputs, not tensors. So, let's use our sample image from the previous step and try some **random horizontal flipping**. But, just to make sure we flip, let's ditch the randomness and make it flip a 100% of times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfdqWGGvjgHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import RandomHorizontalFlip\n",
        "\n",
        "flipper = RandomHorizontalFlip(p=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L638lufj-cW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flipped_img = flipper(sample_img)\n",
        "plt.imshow(flipped_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muk16q5ECi0V",
        "colab_type": "text"
      },
      "source": [
        "Ok, we have a **flipped 5** now.\n",
        "\n",
        "Let's take a look at the other group of transformations now..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKJ6weWFCsXT",
        "colab_type": "text"
      },
      "source": [
        "### Transforms on Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtYjawYQCvGy",
        "colab_type": "text"
      },
      "source": [
        "These are only three transforms that take tensors as inputs: [LinearTransformation](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.LinearTransformation), [Normalize](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Normalize) and [RandomErasing](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomErasing) (although I believe this one was a better fit for the other group of transforms...).\n",
        "\n",
        "Let's apply a **Normalize** transform to our **flipped 5**. But, in order to be able to do that, we need to make it back into a tensor using **ToTensor**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ809kn-kDs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "tensorizer = ToTensor()\n",
        "img_tensor = tensorizer(flipped_img)\n",
        "img_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5JhbrDTDq3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_tensor.min(), img_tensor.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWYsWzG-F46B",
        "colab_type": "text"
      },
      "source": [
        "### Normalize Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvagqAgLD2I8",
        "colab_type": "text"
      },
      "source": [
        "From our image tensor, we see its values are in the **[0, 1]** range.\n",
        "\n",
        "Usually, when dealing with neural networks, it is better to have our inputs in a symmetrical range, like **[-1, 1]**.\n",
        "\n",
        "And that's why we are going to use the **Normalize** transform. From PyTorch's extensive documentation, we get:\n",
        "\n",
        "`Normalize a tensor image with mean and standard deviation.`\n",
        "\n",
        "`Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e.`\n",
        "\n",
        "`input[channel] = (input[channel] - mean[channel]) / std[channel]`\n",
        "\n",
        "So, if we would like to map our [0, 1] range into [-1, 1], we can set our **`mean` to 0.5** and our **`std` to 0.5** as well.\n",
        "\n",
        "This way, we get:\n",
        "- 0 input is transformed into (0 - .5)/.5 = -1\n",
        "- 1 input is transformed into (1 - .5)/.5 = 1\n",
        "\n",
        "---\n",
        "\n",
        "Even though the transform is called **Normalize**, what we have just done with the inputs is actually a **min-max scaling**. We have **NOT** computed the **true mean** and **true standard deviation**, we have just made them equals 0.5 for our convenience.\n",
        "\n",
        "Had we use the true values for both mean and standard deviation, we would have achieved a **standardization**, that is, our data would have **zero mean** and **unit standard deviation**.\n",
        "\n",
        "---\n",
        "\n",
        "Our images have only **1 channel**, so we only need to specify one element in each tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a3qc1VYlCPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import Normalize\n",
        "\n",
        "normalizer = Normalize(mean=(.5,), std=(.5,))\n",
        "normalized_tensor = normalizer(img_tensor)\n",
        "normalized_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMKtP9VPF8zM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "normalized_tensor.min(), normalized_tensor.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTUzjwioGD6O",
        "colab_type": "text"
      },
      "source": [
        "The range is [-1, 1] now.\n",
        "\n",
        "**Mission accomplished!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoXSyugtGJHx",
        "colab_type": "text"
      },
      "source": [
        "### Compose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP1_2p6tGOW8",
        "colab_type": "text"
      },
      "source": [
        "Sure enough, we don't need to do transformations one by one: we can use [**Compose**](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Compose) for that.\n",
        "\n",
        "This is straightforward: line all desired transformations up in a list. This is pretty much the same as a Pipeline in Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaIEJN3TldtN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import Compose\n",
        "\n",
        "composer = Compose([ToPILImage(),\n",
        "                    RandomHorizontalFlip(p=1.0),\n",
        "                    ToTensor(),\n",
        "                    Normalize(mean=(.5,), std=(.5,))])\n",
        "\n",
        "composed_tensor = composer(sample_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLTM0uiPGyXJ",
        "colab_type": "text"
      },
      "source": [
        "The resulting tensor should be exactly the same as the tensor we have transformed step-by-step... let's confirm that:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Falqqiu_mIQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(composed_tensor == normalized_tensor).all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOgaUUeRHf5P",
        "colab_type": "text"
      },
      "source": [
        "### Transforming Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Yk2bRDHiJD",
        "colab_type": "text"
      },
      "source": [
        "The best thing about composing transforms is the fact you can apply them whenever a given data point is being sampled from the dataset.\n",
        "\n",
        "Remember the [**Dataset**](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) class, which torchvision datasets use as parent class? It is possible to call a composed transformation, just like we did, inside the **`__get_item__(self, index)`** method.\n",
        "\n",
        "And that's exactly what torchvision datasets do! You can specify a **transform** argument and, whenever your [**DataLoader**](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) fetches some samples, they will be transformed already! **Beautiful**, uh?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NTbs6vToM5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "new_composer = Compose([RandomHorizontalFlip(p=.5),\n",
        "                        ToTensor(),\n",
        "                        Normalize(mean=(.5,), std=(.5,))])\n",
        "\n",
        "mnist_train = datasets.MNIST('./mnist', train=True, download=True, transform=new_composer)\n",
        "mnist_test = datasets.MNIST('./mnist', train=False, download=True, transform=new_composer)\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(mnist_test, batch_size=128, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sz3fpPMar7gp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_sample = next(iter(train_loader))[0][0]\n",
        "transformed_sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HscbwyVCI7XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformed_sample.min(), transformed_sample.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KLWNERUJHd3",
        "colab_type": "text"
      },
      "source": [
        "Just as expected!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XILRTwMhMgDo",
        "colab_type": "text"
      },
      "source": [
        "## A Simple Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3z6lkpiP2Sko",
        "colab_type": "text"
      },
      "source": [
        "We will use the **MNIST** dataset and build a simple neural network to try classify the hand-written digits.\n",
        "\n",
        "Besides, let's keep it simple and build a **Sequential** model, just like we did with our linear regression.\n",
        "\n",
        "Our input images have 28x28 pixels, that is, 784 pixels in total. Our targets are 10 different classes (digits 0 to 9). So, our model can be structured as follows:\n",
        "\n",
        "- **input layer**: 784 units\n",
        "- **hidden layer(s) and non-linear activations**: we can get creative :-)\n",
        "- **output layer**: 10 units\n",
        "\n",
        "For now, let's use **one hidden layer** with **50 units** and let's use a [**ReLU**](https://pytorch.org/docs/stable/nn.html#relu) as non-linear activation.\n",
        "\n",
        "Since our inputs are 2-dimensional (28x28) and our model has 784 inputs, we still need to add a [**Flatten**](https://pytorch.org/docs/stable/nn.html#flatten) layer at the beginning.\n",
        "\n",
        "So, our model would look like this - let's use [**add_module**](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.add_module) to **name** our layers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8J4I8V-PaQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = nn.Sequential()\n",
        "model.add_module('flatten', nn.Flatten())\n",
        "model.add_module('linear1', nn.Linear(784, 50))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('output', nn.Linear(50, 10))\n",
        "model.to(device)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLVGcbLP9Lhj",
        "colab_type": "text"
      },
      "source": [
        "If we use model's [**named_modules()**](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.named_modules) method, we can retrieve a list of all modules and the model itself!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFYGJbnO9Rsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(model.named_modules())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2uEYbA7xxc",
        "colab_type": "text"
      },
      "source": [
        "And we can use the layers / modules names using dot notation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MM-6xkq6Tmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.linear1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adqDNfrb8ZUE",
        "colab_type": "text"
      },
      "source": [
        "We can also get its corresponding **weights**: `model.linear1.weight`\n",
        "\n",
        "Let's take a look at the weights, plotting them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWrba9dJ71MK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = model.linear1.weight\n",
        "plt.hist(weights.detach().cpu().numpy().reshape(-1,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grGaAust-Fst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(weights.min(), weights.max())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uNp_47r91xX",
        "colab_type": "text"
      },
      "source": [
        "The linear layer has **39200 weights** and we can see they are **uniformly distributed in [-.0357, .0357] range**. Do you think this is a **good initialization scheme**?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8Tgd-bh-g9n",
        "colab_type": "text"
      },
      "source": [
        "### init"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NduRvhTo-kZM",
        "colab_type": "text"
      },
      "source": [
        "Initialization schemes are a big deal! It goes beyond the scope of this tutorial to go into more details, but we'll see how we can **initialize the weights** of a given layer in our neural network.\n",
        "\n",
        "For more details on **weight initialization schemes**, you can check my [post](https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404) out :-)\n",
        "\n",
        "PyTorch has an [**init**](https://pytorch.org/docs/stable/nn.init.html#torch-nn-init) module that has the most common initialization schemes, such as [**kaiming_uniform**](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_uniform_) and [**kaiming_normal**](https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.kaiming_normal_) - also known as **He initialization** - the recommended scheme for using with **ReLU** activation function.\n",
        "\n",
        "Let's use **kaiming_normal_** (notice the **_** - we are making changes **in place**!) to initialize the weights of our linear layer. And let's zero our biases too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5BXrOxF5z8j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.init.kaiming_normal_(model.linear1.weight, mode='fan_in', nonlinearity='relu')\n",
        "nn.init.constant_(model.linear1.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuRsawj1AZDR",
        "colab_type": "text"
      },
      "source": [
        "Did it work? Let's plot it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jmWb3M-9Avr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = model.linear1.weight\n",
        "plt.hist(weights.detach().cpu().numpy().reshape(-1,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3jX9LJdAdBf",
        "colab_type": "text"
      },
      "source": [
        "Awesome! We have succesfully initialized the weights of our network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKxKYVspAkmG",
        "colab_type": "text"
      },
      "source": [
        "### Softmax Layer for Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-CXmxYUSPI7",
        "colab_type": "text"
      },
      "source": [
        "You may be thinking: \"*this is a **multi-class classification** problem... where is the **softmax** layer at the end?*\"\n",
        "\n",
        "Well, you do have a point... but PyTorch makes things a bit confusing here... \n",
        "\n",
        "You **MAY** add a softmax layer at the end or, better yet, a [**LogSoftmax**](https://pytorch.org/docs/stable/nn.html#logsoftmax). If you **DO add it**, you **MUST** use the corresponding negative log-likelihood loss ([**NLLLoss**](https://pytorch.org/docs/stable/nn.html#nllloss)).\n",
        "\n",
        "**BUT**\n",
        "\n",
        "If you **DO NOT** add a **LogSoftmax** layer at the end, you **MUST** use the [**CrossEntropyLoss**](https://pytorch.org/docs/stable/nn.html#crossentropyloss) which, by itself, combines **LogSoftmax AND NLLLoss**.\n",
        "\n",
        "---\n",
        "\n",
        "In summary, you have two options:\n",
        "- **do** add **LogSoftmax** layer at the end and use **NLLLoss**, or\n",
        "- just use **CrossEntropyLoss**\n",
        "\n",
        "---\n",
        "\n",
        "We use the latter, as it is simpler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AB3Q5Xubxpb",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoI3vrWxb2Yb",
        "colab_type": "text"
      },
      "source": [
        "We can also reuse the code from the **Regression** tutorial to perform the model training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxzjBpyk4DdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def train_step(x, y):\n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "        # Step 1: Makes predictions\n",
        "        yhat = model(x)\n",
        "        # Step 2: Computes loss\n",
        "        loss = loss_fn(yhat, y)\n",
        "        # Step 3: Computes gradients\n",
        "        loss.backward()\n",
        "        # Step 4: Updates parameters and zeroes gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "    \n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return train_step\n",
        "\n",
        "def validation(model, loss_fn, val_loader):\n",
        "    # Figures device from where the model parameters (hence, the model) are\n",
        "    device = next(model.parameters()).device.type\n",
        "    val_losses = []\n",
        "\n",
        "    # no gradients in validation!\n",
        "    with torch.no_grad():\n",
        "        val_batch_losses = []\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            # sets model to EVAL mode\n",
        "            model.eval()\n",
        "\n",
        "            # make predictions\n",
        "            yhat = model(x_val)\n",
        "            val_loss = loss_fn(yhat, y_val)\n",
        "            val_batch_losses.append(val_loss.item())\n",
        "\n",
        "        val_losses.append(np.mean(val_batch_losses))\n",
        "\n",
        "    return val_losses\n",
        "\n",
        "\n",
        "def train_loop(model, loss_fn, optimizer, n_epochs, train_loader, val_loader=None):\n",
        "    # Figures device from where the model parameters (hence, the model) are\n",
        "    device = next(model.parameters()).device.type\n",
        "    # Creates the train_step function for our model, loss function and optimizer\n",
        "    train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "    losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        # TRAINING\n",
        "        batch_losses = []\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            loss = train_step(x_batch, y_batch)\n",
        "            batch_losses.append(loss)\n",
        "\n",
        "        losses.append(np.mean(batch_losses))\n",
        "\n",
        "        # VALIDATION\n",
        "        if val_loader is not None:\n",
        "            val_loss = validation(model, loss_fn, val_loader)\n",
        "            val_losses.append(val_loss)\n",
        "\n",
        "        print(\"Epoch {} complete...\".format(epoch))\n",
        "\n",
        "    return losses, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLXIyVvp4TSZ",
        "colab_type": "text"
      },
      "source": [
        "We need to pass some arguments to the **training loop** function:\n",
        "- a **model**: we have one, our neural network\n",
        "- a **loss function**: our problem is a classification and we have not added a softmax layer, so we must use **CrossEntropyLoss**\n",
        "- an **optimizer**: let's stick with **SGD**\n",
        "- the **number of epochs**: since we have a bigger model now, let's use only 10\n",
        "- **data loader(s)**: we have them as well, for the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4or2DZ9ZJwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "lr = 1e-1\n",
        "\n",
        "model = nn.Sequential()\n",
        "model.add_module('flatten', nn.Flatten())\n",
        "model.add_module('linear1', nn.Linear(784, 50))\n",
        "model.add_module('relu1', nn.ReLU())\n",
        "model.add_module('output', nn.Linear(50, 10))\n",
        "model.to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "losses, val_losses = train_loop(model, loss_fn, optimizer, n_epochs, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZORdHKfBay9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm_spjrfb6YJ",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "Isn't it **great**? We loaded the **MNIST dataset**, built a **neural network** model, defined the corresponding **loss function** and **reused everything else**.\n",
        "\n",
        "---\n",
        "\n",
        "What's left to do? We need to check our model's **accuracy** on the validation dataset. So, we make small changes to the **validation loop**, checking which class got the highest probability and matching it against our targets.\n",
        "\n",
        "We can use [**torch.max()**](https://pytorch.org/docs/stable/torch.html#torch.max) with `dim=1` to get both the maximum value (highest predicted probability) and its index (which corresponds to the predicted digit)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p8fmk5LaT_Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        \n",
        "        model.eval()\n",
        "        yhat = model(x_val)\n",
        "        \n",
        "        # this is PyTorch's version of argmax, but it returns a tuple: (max value, index of max value)\n",
        "        _, predicted = torch.max(yhat, 1)\n",
        "        # we get the size of the batch and add up to the total number of samples\n",
        "        total += y_val.size(0)\n",
        "        # we add how many samples got classified correctly\n",
        "        correct += (predicted == y_val).sum().item()\n",
        "        \n",
        "print(correct/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3q9OG1Md7TV",
        "colab_type": "text"
      },
      "source": [
        "**We got around 94% accuracy**!\n",
        "\n",
        "But, can we do better?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbs0SosifnFx",
        "colab_type": "text"
      },
      "source": [
        "## A Convolutional Neural Network (CNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYbh6xG0frH3",
        "colab_type": "text"
      },
      "source": [
        "It is time to try something a bit more sophisticated!\n",
        "\n",
        "Let's create our own model, inheriting from the [**Module**](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) class. It will take one argument, the **number of features** we will create output in our convolution layer.\n",
        "\n",
        "We will use [**Conv2d**](https://pytorch.org/docs/stable/nn.html#conv2d) and [**MaxPool2d**](https://pytorch.org/docs/stable/nn.html#maxpool2d) layers, apart from the already familiar **Linear**, **ReLU** and **Flatten**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq4e5S27fsvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_feature):\n",
        "        super(CNN, self).__init__()\n",
        "        self.n_feature = n_feature\n",
        "        # Creates the convolution layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_feature, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels=n_feature, out_channels=n_feature, kernel_size=5)\n",
        "        # Creates the linear layers\n",
        "        self.fc1 = nn.Linear(n_feature * 4 * 4, 50) # where do this 4 * 4 come from?! check it below\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "        \n",
        "    def forward(self, x, verbose=False):\n",
        "        # Input dimension: (1, 28, 28)\n",
        "        # Output dimension: (n_feature, 24, 24) - we loose (5-1) pixels in each dimension due to the kernel and no padding\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Input dimension (n_feature, 24, 24)\n",
        "        # Output dimension (n_feature, 12, 12)\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "\n",
        "        # Input dimension (n_feature, 12, 12)\n",
        "        # Output dimension (n_feature, 8, 8)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Input dimension (n_feature, 8, 8)\n",
        "        # Output dimension (n_feature, 4, 4) - we loose (5-1) pixels in each dimension due to the kernel and no padding\n",
        "        x = F.max_pool2d(x, kernel_size=2)\n",
        "\n",
        "        # Input dimension (n_feature, 4, 4)\n",
        "        # Output dimension (n_feature * 4 * 4)\n",
        "        x = nn.Flatten()(x)\n",
        "\n",
        "        # Input dimension (n_feature * 4 * 4)\n",
        "        # Output dimension (50)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Input dimension (50)\n",
        "        # Output dimension (10)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-OwXP4Rpb_K",
        "colab_type": "text"
      },
      "source": [
        "### Functional"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxFe_H7SqQU9",
        "colab_type": "text"
      },
      "source": [
        "Maybe you noticed already, but our CNN model used a **mix** of **layers** from both **torch.nn** and **torch.nn.functional**.\n",
        "\n",
        "\"*What is the difference?*\", you ask?\n",
        "\n",
        "PyTorch's [**functional**](https://pytorch.org/docs/stable/nn.functional.html#torch-nn-functional) layers are, er... **functions**.\n",
        "\n",
        "Let's consider two different layers: **2d convolution** and **2d max pooling**. Both can be used as **layer** or **function**:\n",
        "- [**Conv2d**](https://pytorch.org/docs/stable/nn.html#conv2d) or [**F.conv2d**](https://pytorch.org/docs/stable/nn.functional.html#conv2d)\n",
        "- [**MaxPool2d**](https://pytorch.org/docs/stable/nn.html#maxpool2d) or [**F.max_pool2d**](https://pytorch.org/docs/stable/nn.functional.html#max-pool2d)\n",
        "\n",
        "Why did we use a **Conv2d layer** but a **F.max_pool2d function**?\n",
        "\n",
        "Well, on one hand, it is more **convenient** to use `F.max_pool2d(x, kernel_size=2)` instead of `nn.MaxPool2d(kernel_size=2)(x)`. It just looks better, I think...\n",
        "\n",
        "But the thing is, **max pooling layers** do not have **parameters/weights** to be learned! **Convolution layers, do!**\n",
        "\n",
        "Remember the **Nested Model** section? Every **model** or **layer** gets its **parameters** recursively accessed by the parent **model**, **provided they are attributes in the `__init__` method**!\n",
        "\n",
        "---\n",
        "\n",
        "So, it is pretty simple: does the layer has **parameters** that need to be learned?\n",
        "- **YES** - Use **layers** from **torch.nn** and make them **attributes of the parent model**\n",
        "- **NO** - feel free to use **functions** from **torch.nn.functional**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8HNf8JcuG7H",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop\n",
        "\n",
        "Nothing new here, we create an instance of our **CNN model** and send it to the device as usual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQXdlXY6bTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-1\n",
        "\n",
        "model = CNN(n_feature=6).to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHH8U6SvhKyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "n_epochs = 10\n",
        "\n",
        "losses, val_losses = train_loop(model, loss_fn, optimizer, n_epochs, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsDKVvuLhPUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZUzCw2ShPYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        \n",
        "        model.eval()\n",
        "        yhat = model(x_val)\n",
        "        \n",
        "        # this is PyTorch's version of argmax, but it returns a tuple: (max value, index of max value)\n",
        "        _, predicted = torch.max(yhat, 1)\n",
        "        # we get the size of the batch and add up to the total number of samples\n",
        "        total += y_val.size(0)\n",
        "        # we add how many samples got classified correctly\n",
        "        correct += (predicted == y_val).sum().item()\n",
        "        \n",
        "print(correct/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9dwDYZipoxB",
        "colab_type": "text"
      },
      "source": [
        "**Awesome! We are close to 98% accuracy now!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LB65P7O2Mgx",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing Filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LjRN5t5nVTd",
        "colab_type": "text"
      },
      "source": [
        "One of the cool things about Convolution Neural Networks is that its **features** or **filters** can be visualized, so we can have a glimpse of **what the network is looking for** inside the input images :-)\n",
        "\n",
        "We can fetch the **weights** of a convolution layer..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWWZqm5_orhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.conv1.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2cnqfORoy6E",
        "colab_type": "text"
      },
      "source": [
        "This tensor is 6 x 5 x 5... why is that? It has **6 features or filters** (we configured it that way) and each one is **5 x 5** because that's the **kernel size** we defined. No surprises here!\n",
        "\n",
        "But we can think of each one of this 5 x 5 tensors as **an image**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8R9qvqX2RzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Code adapted from \"How to Visualize Filters and Feature Maps in Convolutional Neural Networks\"\n",
        "# by Jason Brownlee\n",
        "# https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "\n",
        "layer_name = 'conv1'\n",
        "# retrieve weights from the hidden layer\n",
        "filters = getattr(model, layer_name).weight.data.cpu().numpy()\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "n_filters, ix = filters.shape[0], 1\n",
        "\n",
        "for i in range(n_filters):\n",
        "    # get the filter\n",
        "    f = filters[i, :, :, :]\n",
        "    # plot each channel separately\n",
        "    for j in range(filters.shape[1]):\n",
        "        # specify subplot and turn of axis\n",
        "        ax = plt.subplot(n_filters, filters.shape[1], ix)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        # plot filter channel in grayscale\n",
        "        plt.imshow(f[j, :, :], cmap='gray')\n",
        "        ix += 1\n",
        "\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfaqU923uhzm",
        "colab_type": "text"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3odfN_Uxb2_5",
        "colab_type": "text"
      },
      "source": [
        "\"Transfer learning is a machine learning method where a model developed for a task is **reused** as the starting point for a model on a second task.\n",
        "\n",
        "It is a popular approach in deep learning where pre-trained models are used as the starting point on computer vision and natural language processing tasks given the vast compute and time resources required to develop neural network models on these problems and from the huge jumps in skill that they provide on related problems.\"\n",
        "\n",
        "Source: [A Gentle Introduction to Transfer Learning for Deep Learning](https://machinelearningmastery.com/transfer-learning-for-deep-learning/)\n",
        "\n",
        "So, let's try using a **pre-trained model** as starting point for classifying MNIST's digits!\n",
        "\n",
        "Let's take one the most **famous** neural network architectures for a spin..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMO04TrFzVgP",
        "colab_type": "text"
      },
      "source": [
        "### AlexNet\n",
        "\n",
        "\"AlexNet was the winning entry in ILSVRC 2012. It solves the problem of image classification where the input is an image of one of 1000 different classes (e.g. cats, dogs etc.) and the output is a vector of 1000 numbers.\"\n",
        "\n",
        "To learn more about AlexNet, check out the post where this excerpt of text comes from: [Understanding AlexNet](https://www.learnopencv.com/understanding-alexnet/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZOWs23X23fM",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://www.learnopencv.com/wp-content/uploads/2018/05/AlexNet-1.png)\n",
        "\n",
        "Source: [Learn OpenCV](https://www.learnopencv.com/understanding-alexnet/)\n",
        "\n",
        "It is actually a bit **too much** to use AlexNet for the purpose of classifying MNIST's digits... but let's go for it anyway!\n",
        "\n",
        "How do we use a **pre-trained model**? We first need to **download its weights** from somewhere and then **load them into the corresponding empty model architecture**.\n",
        "\n",
        "To be honest, PyTorch provides a direct way of directly downloading the weights of AlexNet... but let's make it the **hard way**, downloading it manually and only then **loading them into the model**, so we learn how to actually load it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BC9SujQl5U_e",
        "colab_type": "text"
      },
      "source": [
        "### Loading Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLFX3x2hq1pP",
        "colab_type": "text"
      },
      "source": [
        "Let's start by downloading the pre-trained weights... AlexNet has about 230 Mb!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R3ri2MWbCgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth --output alexnet-owt-4df8aa71.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9rfTwvTq-7B",
        "colab_type": "text"
      },
      "source": [
        "Now, let's create the **empty** network architecture... we could build it from scratch based on the figure above, but it seems too much of a hassle - let's use TorchVision's [**models**](https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models) module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLSyTfHPulGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models import alexnet\n",
        "\n",
        "alex = alexnet()\n",
        "\n",
        "print(alex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT49YuAPrZF5",
        "colab_type": "text"
      },
      "source": [
        "First, we load the file into a **state_dict** (remember those?!) using [**torch.load()**](https://pytorch.org/docs/stable/torch.html#torch.load):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOBHwRTy4rDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_dict = torch.load('alexnet-owt-4df8aa71.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A22QjFRsO7t",
        "colab_type": "text"
      },
      "source": [
        "Then we load the **state_dict** into the **empty architecture** we created. For this step, we use, obviously, the model's [**load_state_dict()**](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.load_state_dict) method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWKEHBpKbial",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alex.load_state_dict(state_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EuuDCSastli",
        "colab_type": "text"
      },
      "source": [
        "### Freezing Layers\n",
        "\n",
        "OK, we have AlexNet locked and loaded! Should we just **start training it?** \n",
        "\n",
        "Well, not so fast... it has 60 million parameters! Besides, **what would be the point of transfer learning then**?\n",
        "\n",
        "So, we are **freezing its layers**, meaning, we **do not want to update its weights**. How do we do that? **Turning gradients OFF!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwKGmOBqu3Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for parameter in alex.parameters():\n",
        "    parameter.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zkP3edgyJeU",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We also need to make a small change... AlexNet was trained to classify **1000 classes**, but we have **only 10 digits**, so we need to **replace the last layer**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDr3cWkFuuKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(alex.classifier)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ6Gy3hou5Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alex.classifier[6] = nn.Linear(4096, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWQylOXkyqik",
        "colab_type": "text"
      },
      "source": [
        "Let's double check if the **only trainable parameters** are the ones from our newly created last layer: **classifier.6**.\n",
        "\n",
        "For this, the model's [**named_parameters()**](https://pytorch.org/docs/stable/nn.html#torch.nn.Module.named_parameters) method come in handy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1y3dPvvu-57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name,param in alex.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "        print(\"\\t\",name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJrFzQJizbjo",
        "colab_type": "text"
      },
      "source": [
        "### Transforming Datasets (again)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkT_jWJ_zSHP",
        "colab_type": "text"
      },
      "source": [
        "AlexNet also expects **different inputs**: 3-channel 224 x 224 images.\n",
        "But our **MNIST** data has single-channel 28 x 28 images. So, we can resort to **transforms** once again to transform the latter into the former."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glayfovRzRi0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.transforms import Resize, Grayscale, ToTensor, Normalize\n",
        "\n",
        "alex_transforms = Compose([Resize(224),\n",
        "                           Grayscale(num_output_channels=3),\n",
        "                           ToTensor(),\n",
        "                           Normalize((.5, .5, .5), (.5, .5, .5)),])\n",
        "\n",
        "mnist_train = datasets.MNIST('./mnist', train=True, download=True, transform=alex_transforms)\n",
        "mnist_test = datasets.MNIST('./mnist', train=False, download=True, transform=alex_transforms)\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(mnist_test, batch_size=128, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3m-_6OQzknP",
        "colab_type": "text"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y92ssOobCApd",
        "colab_type": "text"
      },
      "source": [
        "Nothing new here, but Alex is big, so let's start with 2 epochs only...\n",
        "\n",
        "Also, don't forget to **send Alex to the device** :-)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZBcT9qb60L7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-1\n",
        "\n",
        "model = alex.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfJiG-dKvOMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "n_epochs = 2\n",
        "\n",
        "losses, val_losses = train_loop(model, loss_fn, optimizer, n_epochs, train_loader, val_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2ORqatAwcMI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89KshvVMwfA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x_val, y_val in val_loader:\n",
        "        x_val = x_val.to(device)\n",
        "        y_val = y_val.to(device)\n",
        "        \n",
        "        model.eval()\n",
        "        yhat = model(x_val)\n",
        "        \n",
        "        # this is PyTorch's version of argmax, but it returns a tuple: (max value, index of max value)\n",
        "        _, predicted = torch.max(yhat, 1)\n",
        "        # we get the size of the batch and add up to the total number of samples\n",
        "        total += y_val.size(0)\n",
        "        # we add how many samples got classified correctly\n",
        "        correct += (predicted == y_val).sum().item()\n",
        "        \n",
        "print(correct/total)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI7zQQAh1H4u",
        "colab_type": "text"
      },
      "source": [
        "Doesn't look so impressive now, does it? Anyway..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_9BpAKx5ax7",
        "colab_type": "text"
      },
      "source": [
        "### Saving Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4uddc_t0UZ8",
        "colab_type": "text"
      },
      "source": [
        "As you can see, a **bigger** model like AlexNet takes **quite some time for training each epoch**, even with all but one of its layers **frozen**.\n",
        "\n",
        "So, it is important to be able to **checkpoint** our model, in case we'd like to **restart training later**.\n",
        "\n",
        "To checkpoint a model, we basically have to **save its state** into a file, to **load** it back later - nothing special, actually.\n",
        "\n",
        "What defines the **state of a model**?\n",
        "- **model.state_dict()**: kinda obvious, right?\n",
        "- **optimizer.state_dict()**: remember optimizers had the `state_dict` as well?\n",
        "- **loss**: after all, you should keep track of its evolution\n",
        "- **epoch**: it is just a number, so why not? :-)\n",
        "- **anything else you'd like to have restored**\n",
        "\n",
        "Then, **wrap everything into a Python dictionary** and use [**torch.save()**](https://pytorch.org/docs/stable/torch.html?highlight=save#torch.save) to dump it all into a file! Easy peasy!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQT6KA3g2SRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = {'epoch': n_epochs,\n",
        "              'model_state_dict': model.state_dict(),\n",
        "              'optimizer_state_dict': optimizer.state_dict(),\n",
        "              'loss': losses,\n",
        "              'val_loss': val_losses}\n",
        "\n",
        "torch.save(checkpoint, 'alexnet_checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDe2yStg2tLq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -l alexnet_checkpoint.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjRDtcIC2slJ",
        "colab_type": "text"
      },
      "source": [
        "How would you **load** it back?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5WccAnA2-Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = torch.load('alexnet_checkpoint.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "losses = checkpoint['loss']\n",
        "val_losses = checkpoint['val_loss']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M_DpLoX3FhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwzjTjc93MgP",
        "colab_type": "text"
      },
      "source": [
        "Seems about right...\n",
        "\n",
        "You may save a model for **checkpointing**, like we have just done, or for **making predictions**, assuming training is finished.\n",
        "\n",
        "After loading the model, **DO NOT FORGET**:\n",
        "\n",
        "---\n",
        "\n",
        "**SET THE MODE** (not the mood!):\n",
        "- **checkpointing: model.train()**\n",
        "- **predicting: model.eval()**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1JGN8FIgKSE",
        "colab_type": "text"
      },
      "source": [
        "## Further Improvements\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXy6L02A_idH",
        "colab_type": "text"
      },
      "source": [
        "Is there **anything else** we can improve or change? Sure, there is **always something else** to add to your model — using a [**learning rate scheduler**](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) or a [**learning rate finder**](https://github.com/davidtvs/pytorch-lr-finder).\n",
        "\n",
        "But this tutorial is already waaaaay too long, so I will stop right here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v_kLDpO_1kn",
        "colab_type": "text"
      },
      "source": [
        "## Final Thoughts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6_ZPJMa_5DI",
        "colab_type": "text"
      },
      "source": [
        "I believe this tutorial has **most of the necessary steps** one needs go to trough in order to **learn**, in a **structured** and **incremental** way, how to **develop Deep Learning models for Computer Vision using PyTorch**.\n",
        "\n",
        "Hopefully, after finishing working through all code in this post, you’ll be able to better appreciate and more easily work your way through PyTorch’s official [tutorials](https://pytorch.org/tutorials/).\n",
        "\n",
        "If you have any thoughts, comments or questions, please leave a comment below or contact me on [LinkedIn](https://br.linkedin.com/in/dvgodoy) or [Twitter](https://twitter.com/dvgodoy)."
      ]
    }
  ]
}